# References

[^robbins]: Robbins, H. (1952). Some aspects of the sequential design of experiments. *Bulletin of the American Mathematical Society*, 58(5), 527-535. <a href="https://sci-hub.se/http://dx.doi.org/10.1090/S0002-9904-1952-09620-8" target="_blank">doi:10.1090/S0002-9904-1952-09620-8</a>

[^Johnson]: Johnson, N. L. (1961). Sequential Analysis: A Survey. Journal of the Royal Statistical Society. Series A (General), 124(3), 372.  <a href="https://sci-hub.se/https://doi.org/10.2307/2343243" target="_blank"> doi:10.2307/2343243 </a>

[^Weigl]: Weigl, H. G. (2013). Abraham Wald: a statistician as a key figure for modern econometrics (Doctoral dissertation, Staats-und Universitätsbibliothek Hamburg Carl von Ossietzky). <a href="https://ediss.sub.uni-hamburg.de/handle/ediss/4889" target="_blank">Dissertation Link</a>


[^Agrawal]:Agrawal R. Sample mean based index policies by O(log n) regret for the multi-armed bandit problem. Advances in Applied Probability. 1995;27(4):1054-1078.<a href="https://sci-hub.se/10.2307/1427934" target="_blank">doi:10.2307/1427934 </a>

[^lai1985]: Lai, T. L., & Robbins, H. (1985). Asymptotically efficient adaptive allocation rules. *Advances in Applied Mathematics*, 6(1), 4-22. 

[^Auer]: Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis of the multiarmed bandit problem. *Machine learning*, 47(2), 235-256. <a href="https://homes.di.unimi.it/%7Ecesabian/Pubblicazioni/ml-02.pdf" target="_blank">https://doi.org/10.1023/A:1013689704352 </a>


[^pilarski]: S. Pilarski, S. Pilarski and D. Varró, "Optimal Policy for Bernoulli Bandits: Computation and Algorithm Gauge," in IEEE Transactions on Artificial Intelligence, vol. 2, no. 1, pp. 2-17, Feb. 2021, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9408359" target="_blank"> doi: 10.1109/TAI.2021.3074122 </a>